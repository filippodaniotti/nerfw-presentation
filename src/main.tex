\documentclass[aspectratio=1610]{beamer}
\usepackage{theme}
\usepackage[utf8x]{inputenc}

\usepackage[english]{babel}
\usepackage{calligra}
\usepackage{lmodern}
\usepackage{subcaption}
\usepackage{hyperref}

\usepackage{amsmath,amssymb,amsfonts,physics}
\usepackage{array, booktabs, makecell}
\usepackage{tabularx}

\usepackage{textcomp}
\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother

% Graphics and video
\usepackage{graphicx,float,wrapfig}
\graphicspath{
  {./assets/images/}%
}


% args: big, bigg, Big, Bigg
\newcommand{\parenth}[2][]{#1(#2#1)}
\renewcommand{\bold}[1]{\textbf{\structure{#1}}}
  
\author[Daniotti \and Lucerno]{Filippo Daniotti \and Taylor Lucerno}
\title[NeRF-W]{\textsc{NeRF in the Wild}}
\subtitle{Neural Radiance Fields for Unconstrained Photo Collections}
\institute[DISI - UniTN]{Department of Information Engineering\\and Computer Science}
\date{\today}


\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table of Contents}
        \tableofcontents[currentsection]
    \end{frame}
}

\begin{document}

\begin{frame}
    \titlepage
    \begin{figure}[H]
        \begin{center}
            \includegraphics[width=0.4\linewidth]{marchio_unitrento_colore_it_202002.eps}
        \end{center}
    \end{figure}
\end{frame}


\begin{frame}
    \tableofcontents[sectionstyle=show,subsectionstyle=show/shaded/hide,subsubsectionstyle=show/shaded/hide]
\end{frame}

\section{Introduction}
\begin{frame}{Introduction}
    Content:
    \begin{itemize}
        \item problem statement
        \item NeRF
        \item NeRF in the Wild
    \end{itemize}
\end{frame}

\section{The Problem}
\begin{frame}
    \begin{itemize}
        \item synthesizing novel views of a scene from a sparse set of captured images
        \item doing it in unconstrained environment:
        \begin{itemize}
            \item scene varies amongst training set (illumination, shading, tone)
            \item scene is partially occluded by obstacles
        \end{itemize}
    \end{itemize}
\end{frame}

\section{Background: NeRF}
\begin{frame}{Neural Radiance Fields}
    \begin{block}{In a nutshell}
        Pick a \(F_\Theta\) MLP and make it overfit so the desired scene is encoded within its weights\\\(\rightarrow\) one trained model represents only one scene!
    \end{block}
    \begin{equation*}
        F_\Theta : (\vb{x}, \vb{d}) \rightarrow (\vb{c}, \sigma)
    \end{equation*}
    \begin{itemize}
        \item inputs (obtained from structure-from-motion techniques)
        \begin{itemize}
            \item 3D location \(\vb{x} = (x, y, z)\)
            \item viewing unit-norm direction \(\vb{d} = (d_x, d_y, d_z)\) 
        \end{itemize} 
        \item outputs
        \begin{itemize}
            \item color \(\vb{c} = (r, g, b)\)
            \item volume density \(\sigma(\vb{x})\) 
        \end{itemize}
    \end{itemize}

    To synthesize a novel view, just sample new 3D location and viewing direction
\end{frame}

\begin{frame}{Volume Rendering with Radiance Fields}
    \(\sigma(x) \rightarrow\) differential probability of a camera ray terminating at location \(x\)

    \begin{block}{Expected color}
        
        The expected color \(\hat{\vb{C}}(\vb{r})\) of camera ray \(\vb{r}(t) = \vb{o} + t\vb{d}\) is computed by approximating the rendering integral with numerical quadrature (stratified sampling approach):
        \begin{align}
            \hat{\vb{C}}(\vb{r}) = \mathcal{R}(\vb{r}, \vb{c}, \sigma) = \sum_{k = 1}^{K} T(t_k) \alpha (\sigma (t_k)\delta_k) \vb{c}(t_k),\\
            \textrm{where} \quad T(t_k) = \exp \parenth[\Bigg]{-\sum_{k' = 1}^{k - 1} \sigma (t_{k'}) \delta_{k'}} 
        \end{align}
    \end{block}
    \begin{itemize}
        \item \(T(t_k)\): probability that ray travels without hitting anything - given location \(\vb{x}\) and viewing direction, it expresses how it is likely to find something
        \item \(\alpha(\sigma (t_k)\delta_k) = 1 - \exp(- \sigma (t_k)\delta_k)\) 
        \item \(\delta_k = t_{k-1} - t_k\) (distance between quadrature points)
    \end{itemize}
\end{frame}

\begin{frame}{Architecture}
    Quick note on the architecture:
    \begin{itemize}
        \item the original NeRF uses one single MLP
        \item NeRF-W uses two different MLPs the better enforce the dependencies
        \begin{itemize}
            \item one to estimate density \(\sigma(t)\) and a vector \(\vb{z}(t)\) from the location
            \item one to estimate the color \(\vb{c}(t)\) from the viewing direction and the vector \(\vb{z}(t)\)
        \end{itemize}
    \end{itemize}
    \begin{block}{MLPs}
        \begin{align}
            [\sigma(t), \vb{z}(t)] &= \textrm{MLP}_{\theta_1} (\gamma_{\vb{x}}(\vb{r}(t))) \\
            \vb{c}(t) &= \textrm{MLP}_{\theta_2} (\vb{z}(t), \gamma_{\vb{d}}(\vb{d}))
        \end{align}
    \end{block}
\end{frame}

\begin{frame}{Optimizing NeRFs}
    A few tricks are employed:
    \begin{itemize}
        \item Positional encoding: location vector \(\vb{x}\) is mapped to a higher dimensional space in order to more easily approximate higher-frequency functions
        \item Hierarchical volume sampling: two MLP are actually employed, a coarse one (first) and then a fine one (sampling points for its rays are sampled after the coarse has run for a given training epoch) 
    \end{itemize}
    \begin{block}{Training loss}
        \begin{equation}
            \sum_{\vb{r} \in \mathcal{R}} ||\vb{C}(\vb{r}) - \vb{\hat{C}}^c(\vb{r})||_2^2 + ||\vb{C}(\vb{r}) - \vb{\hat{C}}^f(\vb{r})||_2^2
        \end{equation}
    \end{block}
\end{frame}

\begin{frame}{NeRF Limitations}
    NeRFs assume that the real world scenes are geometrically, phonometrically and materially static, which is often not the case
    \begin{itemize}
        \item phonometric variations: two photographs of a scene taken at different times of day, different periods of the year, atmospheric conditions will vary in terms of illumination, shading, ton quality
        \item transient objects: many real world landmakrs will have a crowd around, possibly captured in the shots
    \end{itemize}
    NeRFs in the wild address these two issues
\end{frame}

\section{Paper contribution: NeRF in the Wild}
\begin{frame}{}

    

\end{frame}

\section{Limitations, possible improvements, future work}
\begin{frame}
    \begin{center}
        Thanks for your attention
    \end{center}
\end{frame}

\end{document}